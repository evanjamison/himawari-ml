name: daily-rollup-phase2

on:
  schedule:
    - cron: "10 9 * * *"
  workflow_dispatch:
    inputs:
      day:
        description: "Optional day (YYYY-MM-DD or YYYYMMDD). Leave blank to auto-detect."
        required: false
        default: ""

permissions:
  contents: write

concurrency:
  group: daily-rollup-phase2
  cancel-in-progress: false

jobs:
  rollup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: data
          fetch-depth: 0

      - name: Configure git identity
        shell: bash
        run: |
          set -euo pipefail
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"

      # Bring code from main into this workspace WITHOUT merging branches
      # IMPORTANT: do NOT overwrite ml/ if you have local edits on the data branch.
      - name: Bring pipeline code from main (no merge)
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main --depth=1

          # Pull pipeline + src code from main
          git checkout origin/main -- src scripts requirements.txt pyproject.toml || true

          # Only pull ml/ from main if it doesn't exist on data
          if [[ ! -f "ml/infer_unet_masks.py" ]]; then
            echo "ml/infer_unet_masks.py missing on data branch; pulling ml/ from main..."
            git checkout origin/main -- ml || true
          else
            echo "Keeping ml/ from data branch (ml/infer_unet_masks.py exists)."
          fi

          echo "---- verify filter_black_frames.py exists ----"
          ls -la scripts/pipeline/filter_black_frames.py

          echo "---- verify Phase2 runner exists ----"
          ls -la scripts/pipeline/run_sample_pipeline.py

          echo "---- verify infer script exists ----"
          ls -la ml/infer_unet_masks.py

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Resolve DAY + input roots
        id: resolve
        shell: bash
        run: |
          set -euo pipefail

          RAWROOT="data/raw"
          INPUT_DAY="${{ github.event.inputs.day }}"

          norm_day() {
            [[ "$1" =~ ^[0-9]{8}$ ]] && echo "${1:0:4}-${1:4:2}-${1:6:2}" || echo "$1"
          }

          [[ -d "$RAWROOT" ]] || { echo "ERROR: $RAWROOT missing on data branch"; exit 1; }

          mapfile -t DAYS < <(find "$RAWROOT" -maxdepth 1 -mindepth 1 -type d -name "????-??-??" -printf "%f|%p\n" | sort)

          if [[ ${#DAYS[@]} -eq 0 ]]; then
            echo "ERROR: No YYYY-MM-DD folders under $RAWROOT"
            ls -la "$RAWROOT" || true
            exit 1
          fi

          if [[ -n "$INPUT_DAY" ]]; then
            DAY="$(norm_day "$INPUT_DAY")"
            DAYDIR="$(printf '%s\n' "${DAYS[@]}" | awk -F'|' -v d="$DAY" '$1==d {print $2}' | tail -n 1)"
            [[ -n "$DAYDIR" ]] || { echo "ERROR: day '$DAY' not found under $RAWROOT"; exit 1; }
          else
            LAST="${DAYS[-1]}"
            DAY="${LAST%%|*}"
            DAYDIR="${LAST#*|}"
          fi

          if [[ -d "$DAYDIR/latest" ]]; then
            INROOT="$DAYDIR/latest"
          elif [[ -d "$DAYDIR/sequences" ]]; then
            INROOT="$DAYDIR/sequences"
          else
            echo "ERROR: Neither latest/ nor sequences/ exists in $DAYDIR"
            ls -la "$DAYDIR" || true
            exit 1
          fi

          OUTMASTER="$DAYDIR/master"
          OUTFRAMES="$OUTMASTER/frames"
          OUTDIR="out/$DAY/daily"

          echo "day=$DAY" >> "$GITHUB_OUTPUT"
          echo "daydir=$DAYDIR" >> "$GITHUB_OUTPUT"
          echo "inroot=$INROOT" >> "$GITHUB_OUTPUT"
          echo "outmaster=$OUTMASTER" >> "$GITHUB_OUTPUT"
          echo "outframes=$OUTFRAMES" >> "$GITHUB_OUTPUT"
          echo "outdir=$OUTDIR" >> "$GITHUB_OUTPUT"

      - name: Filter black frames (pre-stage)
        id: filter
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.resolve.outputs.inroot }}"
          DAYDIR="${{ steps.resolve.outputs.daydir }}"

          CLEANROOT="$DAYDIR/filtered"
          QUAR="$DAYDIR/rejects/black"

          mkdir -p "$CLEANROOT" "$QUAR"

          python scripts/pipeline/filter_black_frames.py \
            --inputs "$INROOT" \
            --outdir "$CLEANROOT" \
            --quarantine "$QUAR" \
            --mean-max 6 \
            --std-max 6 \
            --mode copy

          echo "cleanroot=$CLEANROOT" >> "$GITHUB_OUTPUT"

      - name: Stage frames by copying CLEANROOT -> master/frames
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.filter.outputs.cleanroot }}"
          OUTFRAMES="${{ steps.resolve.outputs.outframes }}"

          mkdir -p "$OUTFRAMES"

          shopt -s globstar nullglob
          COPIED=0
          for f in "$INROOT"/**/*.png "$INROOT"/*.png; do
            if [[ -f "$f" ]]; then
              cp -f "$f" "$OUTFRAMES/"
              COPIED=$((COPIED+1))
            fi
          done

          echo "Copied $COPIED png files into $OUTFRAMES"

          if [[ "$COPIED" -eq 0 ]]; then
            echo "ERROR: No PNG frames found under cleaned root: $INROOT"
            exit 1
          fi

      - name: Run Phase 2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${{ steps.resolve.outputs.outdir }}"

          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          python scripts/pipeline/run_sample_pipeline.py \
            --raw-dir "$RAWDIR" \
            --outdir "${{ steps.resolve.outputs.outdir }}" \
            --save-overlays

      # -------------------------
      # Phase 3: U-Net inference (auto-threshold)
      # -------------------------
      - name: Resolve U-Net model checkpoint
        id: model
        shell: bash
        run: |
          set -euo pipefail

          CANON="out/models/unet_cloudmask_latest.pt"
          if [[ -f "$CANON" ]]; then
            echo "model_path=$CANON" >> "$GITHUB_OUTPUT"
            echo "Using canonical: $CANON"
            exit 0
          fi

          echo "Canonical missing: $CANON"
          echo "Searching for newest *.pt under out/models..."
          mapfile -t CANDS < <(find out/models -type f -name "*.pt" -printf "%T@|%p\n" | sort -nr | head -n 1 | cut -d'|' -f2-)

          if [[ ${#CANDS[@]} -eq 0 ]]; then
            echo "ERROR: No model .pt found under out/models in this checkout."
            exit 1
          fi

          echo "model_path=${CANDS[0]}" >> "$GITHUB_OUTPUT"
          echo "Using newest: ${CANDS[0]}"

      - name: Pick a good threshold automatically (TEMP)
        id: thr
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          FRAMES="${{ steps.resolve.outputs.outframes }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"

          # Target average predicted cloud coverage (white%) on the masks.
          # If you're getting "too white", LOWER this (e.g., 3.0). If "too black", RAISE (e.g., 12.0).
          TARGET_WHITE_PCT="7.0"

          echo "DAY=$DAY"
          echo "FRAMES=$FRAMES"
          echo "MODEL_PATH=$MODEL_PATH"
          echo "TARGET_WHITE_PCT=$TARGET_WHITE_PCT"

          python - << 'PY'
          import os, random
          from pathlib import Path
          import numpy as np
          import torch
          from PIL import Image

          day = os.environ["DAY"]
          frames_dir = Path(os.environ["FRAMES"])
          ckpt_path = Path(os.environ["MODEL_PATH"])
          target = float(os.environ["TARGET_WHITE_PCT"])

          # Import the same model builder your infer script uses
          # (infer_unet_masks.py defines UNetSmall + load logic)
          from ml.infer_unet_masks import UNetSmall  # type: ignore

          ckpt = torch.load(str(ckpt_path), map_location="cpu")
          state = ckpt["state_dict"] if isinstance(ckpt, dict) and "state_dict" in ckpt else ckpt

          # Infer base_ch/depth if present; otherwise default to what you trained with
          base = int(ckpt.get("base_ch", 32)) if isinstance(ckpt, dict) else 32
          depth = int(ckpt.get("depth", 3)) if isinstance(ckpt, dict) else 3

          model = UNetSmall(in_channels=3, out_channels=1, base_ch=base, depth=depth)
          model.load_state_dict(state, strict=False)
          model.eval()

          files = sorted(frames_dir.glob("*.png"))
          if not files:
            raise SystemExit(f"No frames found in {frames_dir}")

          # sample up to 12 frames across the day
          n = min(12, len(files))
          idxs = np.linspace(0, len(files) - 1, n).astype(int).tolist()
          sample = [files[i] for i in idxs]

          # thresholds to test (covers both your extremes)
          thresholds = [0.05, 0.07, 0.09, 0.10, 0.11, 0.12, 0.13, 0.15, 0.18, 0.22, 0.30]

          def run_on_image(p: Path):
            img = np.array(Image.open(p).convert("RGB")).astype(np.float32) / 255.0
            x = torch.from_numpy(img).permute(2,0,1).unsqueeze(0)
            with torch.no_grad():
              logits = model(x)
              prob = torch.sigmoid(logits).squeeze().cpu().numpy()
            return prob

          # compute mean white% per threshold over sample
          table = []
          for t in thresholds:
            whites = []
            for p in sample:
              prob = run_on_image(p)
              whites.append(float((prob > t).mean() * 100.0))
            table.append((t, float(np.mean(whites)), float(np.std(whites))))
          # pick threshold closest to target mean white%
          best = min(table, key=lambda r: abs(r[1] - target))

          print("---- threshold sweep (t, mean_white%, std) ----")
          for t, m, s in table:
            print(f"{t:>5}  mean={m:6.2f}%  std={s:6.2f}%")
          print(f"\nCHOSEN_THRESHOLD={best[0]} (target {target}%, mean {best[1]:.2f}%)")

          # write chosen threshold for Actions output
          out = Path(os.environ["GITHUB_OUTPUT"])
          out.write_text(out.read_text() + f"threshold={best[0]}\n")
          PY
        env:
          DAY: ${{ steps.resolve.outputs.day }}
          FRAMES: ${{ steps.resolve.outputs.outframes }}
          MODEL_PATH: ${{ steps.model.outputs.model_path }}
          
      # -------------------------
      # TEMP DEBUG (REMOVE AFTER FIXED)
      # Inspect model output distribution on 1 real frame using
      # the exact same code paths as ml/infer_unet_masks.py
      # -------------------------
      - name: DEBUG Phase 3 â€” inspect frame + logits/prob stats (TEMP)
        shell: bash
        run: |
          set -euo pipefail

          python - << 'PY'
          from pathlib import Path
          import numpy as np
          import torch

          import ml.infer_unet_masks as inf

          frames_dir = Path(r"${{ steps.resolve.outputs.outframes }}")
          model_path = Path(r"${{ steps.model.outputs.model_path }}")

          # pick a deterministic sample frame
          frames = sorted(frames_dir.glob("*.png"))
          print("DEBUG Phase 3")
          print("Frames dir:", frames_dir)
          print("Model path:", model_path)
          print("Model exists:", model_path.exists())
          print("Frame count:", len(frames))
          if not frames:
            raise SystemExit("ERROR: no frames found to debug")

          sample = frames[0]
          print("Sample frame:", sample.name)

          device = torch.device("cpu")

          # load checkpoint + build model exactly like infer_unet_masks.py
          ckpt_obj = torch.load(model_path, map_location=device)
          sd = inf.normalize_keys(inf.extract_state_dict(ckpt_obj))
          base, depth = inf.infer_base_and_depth(sd)
          print("Inferred base/depth:", base, depth)

          if depth == 3:
            model = inf.UNet3(in_ch=3, base=base, out_ch=1).to(device)
          else:
            model = inf.UNet4(in_ch=3, base=base, out_ch=1).to(device)

          model.load_state_dict(sd, strict=True)
          model.eval()

          x = inf.load_rgb(sample, 256)
          xt = torch.from_numpy(x).unsqueeze(0).to(device)

          with torch.no_grad():
            logits = model(xt)[0,0].cpu().numpy()
            prob = 1.0 / (1.0 + np.exp(-logits))

          thr = 0.3
          print("Input tensor stats:", "min", float(x.min()), "max", float(x.max()), "mean", float(x.mean()))
          print("Logits stats:", "min", float(logits.min()), "max", float(logits.max()), "mean", float(logits.mean()))
          print("Prob stats:", "min", float(prob.min()), "max", float(prob.max()), "mean", float(prob.mean()))
          print(f"Pct(prob >= {thr}):", float((prob >= thr).mean()) * 100.0)

          print("DEBUG COMPLETE")
          PY

      - name: Run Phase 3 (U-Net inference) using auto threshold
        id: phase3
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          FRAMES="${{ steps.resolve.outputs.outframes }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"
          THR="${{ steps.thr.outputs.threshold }}"
          OUTDIR="out/${DAY}/phase3_unet_v2_auto"

          echo "DAY=$DAY"
          echo "FRAMES=$FRAMES"
          echo "MODEL_PATH=$MODEL_PATH"
          echo "THR=$THR"
          echo "OUTDIR=$OUTDIR"

          mkdir -p "$OUTDIR"

          python ml/infer_unet_masks.py \
            --frames "$FRAMES" \
            --outdir "$OUTDIR" \
            --ckpt "$MODEL_PATH" \
            --recursive \
            --threshold "$THR" \
            --image-size 256 \
            --device cpu

          echo "---- quick mask sanity (first 10 white%) ----"
          python - << 'PY'
          from pathlib import Path
          import numpy as np
          from PIL import Image

          p = Path("out") / "${{ steps.resolve.outputs.day }}" / "phase3_unet_v2_auto" / "masks_unet"
          files = sorted(p.glob("*.png"))
          print("masks_unet:", p)
          print("count:", len(files))
          for f in files[:10]:
            a = np.array(Image.open(f))
            white = float((a > 0).mean()) * 100.0
            print(f.name, "min/max", int(a.min()), int(a.max()), "white%:", round(white, 4))
          PY

      - name: Upload Phase 3 outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: phase3_unet_${{ steps.resolve.outputs.day }}
          path: out/${{ steps.resolve.outputs.day }}/phase3_unet_v2_thr03

      - name: Commit results to data
        shell: bash
        run: |
          set -euo pipefail
          git add -f data/raw out || true
          git commit -m "daily rollup + phase2 + phase3(thr=0.3): ${{ steps.resolve.outputs.day }}" || echo "No changes"
          git push origin data

