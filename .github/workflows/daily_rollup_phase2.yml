name: daily-rollup-phase2

on:
  schedule:
    - cron: "10 9 * * *"
  workflow_dispatch:
    inputs:
      day:
        description: "Optional day (YYYY-MM-DD or YYYYMMDD). Leave blank to auto-detect."
        required: false
        default: ""
      phase3_mode:
        description: "Phase 3 mode: metrics (teacher->train->infer) or seg (pixel-mask U-Net)."
        required: false
        default: "seg"
      enable_phase4:
        description: "Run Phase 4 ConvLSTM training (1=yes, 0=no)."
        required: false
        default: "1"
      convlstm_use_rgb:
        description: "ConvLSTM input includes RGB frames (1=yes) vs grayscale (0=no)."
        required: false
        default: "0"
      convlstm_seq_len:
        description: "ConvLSTM sequence length (T)."
        required: false
        default: "6"
      convlstm_rollout_k:
        description: "ConvLSTM rollout steps (K)."
        required: false
        default: "2"
      convlstm_epochs:
        description: "ConvLSTM epochs."
        required: false
        default: "20"

permissions:
  contents: write

concurrency:
  group: daily-rollup-phase2
  cancel-in-progress: false

jobs:
  rollup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: data
          fetch-depth: 0

      - name: Configure git identity
        shell: bash
        run: |
          set -euo pipefail
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"

      # Bring code from main into this workspace WITHOUT merging branches
      - name: Bring pipeline code from main (no merge)
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main --depth=1
          git checkout origin/main -- src scripts ml requirements.txt pyproject.toml || true

          echo "---- verify key scripts exist ----"
          ls -la scripts/pipeline/filter_black_frames.py
          ls -la scripts/pipeline/run_sample_pipeline.py
          ls -la scripts/experiments/segmentation/cloud_mask_baseline_v2.py

          echo "---- verify phase3 trainers/infer exist ----"
          ls -la ml/train_unet.py
          ls -la ml/train_unet_pixelmask.py || true
          ls -la ml/infer_unet_masks.py
          ls -la ml/infer_unet_pixelmask.py || true

          echo "---- verify convlstm trainer exists ----"
          ls -la ml/train_convlstm.py || true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .
          # baseline v2 imports cv2; use headless OpenCV on GH runners
          pip install opencv-python-headless

      - name: Resolve DAY + input roots + Phase 3 mode
        id: resolve
        shell: bash
        run: |
          set -euo pipefail

          RAWROOT="data/raw"
          INPUT_DAY="${{ github.event.inputs.day }}"
          MODE_IN="${{ github.event.inputs.phase3_mode }}"

          norm_day() {
            [[ "$1" =~ ^[0-9]{8}$ ]] && echo "${1:0:4}-${1:4:2}-${1:6:2}" || echo "$1"
          }

          [[ -d "$RAWROOT" ]] || { echo "ERROR: $RAWROOT missing on data branch"; exit 1; }

          mapfile -t DAYS < <(find "$RAWROOT" -maxdepth 1 -mindepth 1 -type d -name "????-??-??" -printf "%f|%p\n" | sort)

          if [[ ${#DAYS[@]} -eq 0 ]]; then
            echo "ERROR: No YYYY-MM-DD folders under $RAWROOT"
            ls -la "$RAWROOT" || true
            exit 1
          fi

          if [[ -n "$INPUT_DAY" ]]; then
            DAY="$(norm_day "$INPUT_DAY")"
            DAYDIR="$(printf '%s\n' "${DAYS[@]}" | awk -F'|' -v d="$DAY" '$1==d {print $2}' | tail -n 1)"
            [[ -n "$DAYDIR" ]] || { echo "ERROR: day '$DAY' not found under $RAWROOT"; exit 1; }
          else
            LAST="${DAYS[-1]}"
            DAY="${LAST%%|*}"
            DAYDIR="${LAST#*|}"
          fi

          if [[ -d "$DAYDIR/latest" ]]; then
            INROOT="$DAYDIR/latest"
          elif [[ -d "$DAYDIR/sequences" ]]; then
            INROOT="$DAYDIR/sequences"
          else
            echo "ERROR: Neither latest/ nor sequences/ exists in $DAYDIR"
            ls -la "$DAYDIR" || true
            exit 1
          fi

          # normalize mode
          MODE="seg"
          if [[ "$MODE_IN" == "metrics" ]]; then MODE="metrics"; fi

          OUTMASTER="$DAYDIR/master"
          OUTFRAMES="$OUTMASTER/frames"
          OUTDIR="out/$DAY/daily"

          echo "day=$DAY" >> "$GITHUB_OUTPUT"
          echo "daydir=$DAYDIR" >> "$GITHUB_OUTPUT"
          echo "inroot=$INROOT" >> "$GITHUB_OUTPUT"
          echo "outmaster=$OUTMASTER" >> "$GITHUB_OUTPUT"
          echo "outframes=$OUTFRAMES" >> "$GITHUB_OUTPUT"
          echo "outdir=$OUTDIR" >> "$GITHUB_OUTPUT"
          echo "phase3_mode=$MODE" >> "$GITHUB_OUTPUT"

          echo "Resolved DAY=$DAY"
          echo "Resolved MODE=$MODE"
          echo "Resolved INROOT=$INROOT"
          echo "Resolved DAYDIR=$DAYDIR"

      - name: Filter black frames (pre-stage)
        id: filter
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.resolve.outputs.inroot }}"
          DAYDIR="${{ steps.resolve.outputs.daydir }}"

          CLEANROOT="$DAYDIR/filtered"
          QUAR="$DAYDIR/rejects/black"

          mkdir -p "$CLEANROOT" "$QUAR"

          python scripts/pipeline/filter_black_frames.py \
            --inputs "$INROOT" \
            --outdir "$CLEANROOT" \
            --quarantine "$QUAR" \
            --mean-max 6 \
            --std-max 6 \
            --mode copy

          echo "cleanroot=$CLEANROOT" >> "$GITHUB_OUTPUT"

      - name: Stage frames by copying CLEANROOT -> master/frames
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.filter.outputs.cleanroot }}"
          OUTFRAMES="${{ steps.resolve.outputs.outframes }}"

          mkdir -p "$OUTFRAMES"

          shopt -s globstar nullglob
          COPIED=0
          for f in "$INROOT"/**/*.png "$INROOT"/*.png; do
            if [[ -f "$f" ]]; then
              cp -f "$f" "$OUTFRAMES/"
              COPIED=$((COPIED+1))
            fi
          done

          echo "Copied $COPIED png files into $OUTFRAMES"

          if [[ "$COPIED" -eq 0 ]]; then
            echo "ERROR: No PNG frames found under cleaned root: $INROOT"
            exit 1
          fi

      - name: Run Phase 2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${{ steps.resolve.outputs.outdir }}"

          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          python scripts/pipeline/run_sample_pipeline.py \
            --raw-dir "$RAWDIR" \
            --outdir "${{ steps.resolve.outputs.outdir }}" \
            --save-overlays

      # ============================================================
      # Phase 3: branchable mode
      #   metrics: baseline_v2 -> train_unet.py -> infer_unet_masks.py (disk mask ON)
      #   seg:     baseline_v2 -> train_unet_pixelmask.py -> infer_unet_pixelmask.py (disk mask OFF)
      # ============================================================

      - name: Phase 3A - Build teacher masks + cloud_metrics.csv (baseline v2)
        shell: bash
        run: |
          set -euo pipefail
          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          python scripts/experiments/segmentation/cloud_mask_baseline_v2.py \
            --raw-dir "$RAWDIR" \
            --outdir out \
            --image-size 256 \
            --save-overlays

          echo "---- verify teacher outputs ----"
          ls -la out/cloud_metrics.csv
          ls -la out/masks | head -n 20 || true

      - name: Phase 3B - Train model (metrics OR seg)
        id: p3train
        shell: bash
        run: |
          set -euo pipefail
          MODE="${{ steps.resolve.outputs.phase3_mode }}"
          echo "Phase3 MODE=$MODE"

          if [[ "$MODE" == "metrics" ]]; then
            # teacher-metrics training (disk mask ON)
            python ml/train_unet.py \
              --metrics-csv out/cloud_metrics.csv \
              --outdir out \
              --epochs 30 \
              --batch-size 4 \
              --lr 3e-4 \
              --base-ch 32 \
              --augment \
              --bce-weight 0.1 \
              --use-disk-mask \
              --pos-weight auto \
              --split-by-time

            echo "model_path=out/models/unet_cloudmask_latest.pt" >> "$GITHUB_OUTPUT"
            echo "outtag=cloudmask" >> "$GITHUB_OUTPUT"
            echo "use_disk=1" >> "$GITHUB_OUTPUT"

          else
            # pixel-mask segmentation training (disk mask OFF)
            # IMPORTANT:
            #  - train_unet_pixelmask.py expects --frames-dir and --masks-dir
            #  - it does NOT support --pos-weight auto (must be float)
            python ml/train_unet_pixelmask.py \
              --frames-dir "${{ steps.resolve.outputs.outframes }}" \
              --masks-dir  out/masks \
              --outdir out \
              --image-size 256 \
              --epochs 30 \
              --batch-size 4 \
              --lr 3e-4 \
              --base-ch 32 \
              --augment \
              --bce-weight 0.5 \
              --pos-weight 3.0 \
              --split-by-time

            echo "model_path=out/models/unet_pixelmask_latest.pt" >> "$GITHUB_OUTPUT"
            echo "outtag=pixelmask" >> "$GITHUB_OUTPUT"
            echo "use_disk=0" >> "$GITHUB_OUTPUT"
          fi

          echo "---- list models ----"
          ls -la out/models | head -n 200 || true


      - name: Phase 3C - Debug checkpoint identity
        shell: bash
        run: |
          set -euo pipefail
          MODEL_PATH="${{ steps.p3train.outputs.model_path }}"
          test -f "$MODEL_PATH" || { echo "ERROR: missing model: $MODEL_PATH"; exit 1; }

          python - <<'PY'
          import torch, os
          p = os.environ["MODEL_PATH"]
          ckpt = torch.load(p, map_location="cpu")
          print("MODEL_PATH:", p)
          print("ckpt type:", type(ckpt))
          if isinstance(ckpt, dict):
              cfg = ckpt.get("config", {})
              print("run_id:", cfg.get("run_id"))
              print("use_disk_mask:", cfg.get("use_disk_mask"))
              print("pos_weight:", cfg.get("pos_weight"))
              print("bce_weight:", cfg.get("bce_weight"))
          PY
        env:
          MODEL_PATH: ${{ steps.p3train.outputs.model_path }}

      # -------------------------
      # Phase 3D - Infer (multi-threshold) + debug pixel stats
      #   - seg mode: use infer_unet_pixelmask.py (no disk mask)
      #   - metrics mode: use infer_unet_masks.py (disk mask on)
      # -------------------------
      - name: Phase 3D - Infer masks (multi-threshold) + debug pixel stats
        id: p3infer
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          RAWDIR="${{ steps.resolve.outputs.outframes }}"
          MODE="${{ steps.resolve.outputs.phase3_mode }}"
          MODEL_PATH="${{ steps.p3train.outputs.model_path }}"
          OUTTAG="${{ steps.p3train.outputs.outtag }}"
          USE_DISK="${{ steps.p3train.outputs.use_disk }}"

          echo "DAY=$DAY"
          echo "RAWDIR=$RAWDIR"
          echo "MODE=$MODE"
          echo "MODEL_PATH=$MODEL_PATH"
          echo "OUTTAG=$OUTTAG"
          echo "USE_DISK=$USE_DISK"

          test -d "$RAWDIR" || { echo "ERROR: frames dir missing: $RAWDIR"; exit 1; }
          test -f "$MODEL_PATH" || { echo "ERROR: model missing: $MODEL_PATH"; exit 1; }

          THRS="0.3 0.5 0.6 0.7 0.8"
          CANON_OUT="out/$DAY/phase3_unet_${OUTTAG}_thr03"

          for T in $THRS; do
            OUTDIR="out/$DAY/phase3_unet_${OUTTAG}_thr${T/./}"
            echo "---- infer threshold=$T -> $OUTDIR ----"
            mkdir -p "$OUTDIR"

            if [[ "$MODE" == "seg" ]]; then
              # pixelmask inference entrypoint (new)
              python ml/infer_unet_pixelmask.py \
                --frames "$RAWDIR" \
                --outdir "$OUTDIR" \
                --ckpt "$MODEL_PATH" \
                --recursive \
                --threshold "$T" \
                --image-size 256 \
                --device cpu
            else
              # metrics inference entrypoint (existing)
              if [[ "$USE_DISK" == "1" ]]; then
                python ml/infer_unet_masks.py \
                  --frames "$RAWDIR" \
                  --outdir "$OUTDIR" \
                  --ckpt "$MODEL_PATH" \
                  --recursive \
                  --threshold "$T" \
                  --image-size 256 \
                  --device cpu \
                  --use-disk-mask \
                  --disk-thresh 0.02
              else
                python ml/infer_unet_masks.py \
                  --frames "$RAWDIR" \
                  --outdir "$OUTDIR" \
                  --ckpt "$MODEL_PATH" \
                  --recursive \
                  --threshold "$T" \
                  --image-size 256 \
                  --device cpu
              fi
            fi

            OUTDIR="$OUTDIR" python -c $'from pathlib import Path\nimport os\nimport numpy as np\nfrom PIL import Image\n\noutdir = Path(os.environ["OUTDIR"]) / "masks_unet"\nfiles = sorted(outdir.glob("*.png"))\nprint("masks_unet:", outdir)\nprint("count:", len(files))\nif not files:\n    raise SystemExit("No mask PNGs found.")\n\nfor f in files[:5]:\n    a = np.array(Image.open(f).convert("L"))\n    white = (a >= 128).mean() * 100.0\n    print(f.name, "shape", a.shape, "min/max", int(a.min()), int(a.max()), "white%:", round(white, 4))\n'

            ls -la "$OUTDIR/masks_unet" | head -n 10 || true
            ls -la "$OUTDIR/cloud_metrics_unet.csv" || true
          done

          # canonical = thr03
          test -d "$CANON_OUT/masks_unet" || { echo "ERROR: canonical output missing: $CANON_OUT/masks_unet"; exit 1; }

          # hard fail if canonical masks are all black
          CANON_OUT="$CANON_OUT" python -c $'from pathlib import Path\nimport os\nimport numpy as np\nfrom PIL import Image\n\noutdir = Path(os.environ["CANON_OUT"]) / "masks_unet"\nmasks = sorted(outdir.glob("*.png"))[:10]\nprint("canonical check:", outdir)\nprint("checking", len(masks), "masks")\nif not masks:\n    raise SystemExit("No canonical mask PNGs found.")\n\nbad = 0\nfor p in masks:\n    a = np.array(Image.open(p).convert("L"))\n    if a.max() == 0:\n        bad += 1\n    print(p.name, "min/max", int(a.min()), int(a.max()), "white%:", float((a > 0).mean() * 100.0))\n\nif bad == len(masks):\n    raise SystemExit("All checked canonical masks are empty (all black). Failing.")\n'

          echo "canon_out=$CANON_OUT" >> "$GITHUB_OUTPUT"

      # ============================================================
      # Phase 4: ConvLSTM training ON GitHub Actions
      #   - uses canonical Phase3 thr03 masks + raw frames
      #   - builds a metrics CSV for train_convlstm.py
      # ============================================================

      - name: Phase 4A - Build ConvLSTM metrics CSV from Phase 3 canonical output
        if: ${{ github.event.inputs.enable_phase4 != '0' }}
        id: p4csv
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          RAWDIR="${{ steps.resolve.outputs.outframes }}"
          CANON_OUT="${{ steps.p3infer.outputs.canon_out }}"

          OUTROOT="out/$DAY/phase4_convlstm"
          mkdir -p "$OUTROOT"

          echo "DAY=$DAY"
          echo "RAWDIR=$RAWDIR"
          echo "CANON_OUT=$CANON_OUT"
          echo "OUTROOT=$OUTROOT"

          test -d "$RAWDIR" || { echo "ERROR: RAWDIR missing: $RAWDIR"; exit 1; }
          test -d "$CANON_OUT/masks_unet" || { echo "ERROR: masks missing: $CANON_OUT/masks_unet"; exit 1; }

          python - <<'PY'
          from pathlib import Path
          import re
          import pandas as pd

          day = Path("${{ steps.resolve.outputs.day }}")
          rawdir = Path("${{ steps.resolve.outputs.outframes }}")
          canon = Path("${{ steps.p3infer.outputs.canon_out }}") / "masks_unet"
          outcsv = Path("out") / str(day) / "phase4_convlstm" / "convlstm_metrics.csv"

          def ts_from_name(name: str):
              # expects himawari_YYYYMMDDTHHMMSSZ.png
              m = re.search(r"himawari_(\d{8}T\d{6})Z", name)
              return m.group(1) + "Z" if m else None

          frames = sorted(rawdir.glob("*.png"))
          rows = []
          for f in frames:
              ts = ts_from_name(f.name)
              if ts is None:
                  continue
              mask = canon / f"{f.stem}_mask.png"
              if not mask.exists():
                  # some pipelines may name mask exactly as frame + _mask
                  # (this is the expected path here)
                  continue

              rows.append({
                  "timestamp_utc": ts,
                  # RELATIVE paths from repo root (train_convlstm.py expects relative)
                  "image_path": str(f).replace("\\", "/"),
                  "mask_path": str(mask).replace("\\", "/"),
              })

          df = pd.DataFrame(rows).sort_values("timestamp_utc").reset_index(drop=True)
          outcsv.parent.mkdir(parents=True, exist_ok=True)
          df.to_csv(outcsv, index=False)

          print("Wrote:", outcsv)
          print("rows:", len(df))
          print(df.head(3).to_string(index=False))
          if len(df) < 4:
              raise SystemExit("Not enough (frame,mask) pairs to train ConvLSTM (need at least a few).")
          PY

          echo "metrics_csv=out/$DAY/phase4_convlstm/convlstm_metrics.csv" >> "$GITHUB_OUTPUT"

      - name: Phase 4B - Train ConvLSTM (scheduled sampling)
        if: ${{ github.event.inputs.enable_phase4 != '0' }}
        shell: bash
        run: |
          set -euo pipefail

          METRICS="${{ steps.p4csv.outputs.metrics_csv }}"
          test -f "$METRICS" || { echo "ERROR: missing ConvLSTM metrics csv: $METRICS"; exit 1; }

          echo "---- ConvLSTM metrics sanity ----"
          python - <<'PY'
          import pandas as pd
          df = pd.read_csv("${METRICS}")
          print("rows:", len(df))
          print("head:", df.head(2).to_dict(orient="records"))
          print("tail:", df.tail(2).to_dict(orient="records"))
          PY

          USE_RGB="${{ github.event.inputs.convlstm_use_rgb }}"
          SEQ_LEN="${{ github.event.inputs.convlstm_seq_len }}"
          K="${{ github.event.inputs.convlstm_rollout_k }}"
          EPOCHS="${{ github.event.inputs.convlstm_epochs }}"

          echo "METRICS=$METRICS"
          echo "USE_RGB=$USE_RGB"
          echo "SEQ_LEN=$SEQ_LEN"
          echo "K=$K"
          echo "EPOCHS=$EPOCHS"

          # -----------------------------
          # SMOKE RUN (fast, proves liveness)
          # -----------------------------
          echo "---- SMOKE RUN (epochs=1, rollout_k=1) ----"
          if [[ "$USE_RGB" == "1" ]]; then
            python -u ml/train_convlstm.py \
              --metrics-csv "$METRICS" \
              --outdir out \
              --seq-len "$SEQ_LEN" \
              --rollout-k 1 \
              --epochs 1 \
              --batch-size 2 \
              --use-rgb
          else
            python -u ml/train_convlstm.py \
              --metrics-csv "$METRICS" \
              --outdir out \
              --seq-len "$SEQ_LEN" \
              --rollout-k 1 \
              --epochs 1 \
              --batch-size 2
          fi

          # -----------------------------
          # REAL RUN (keep it practical on CPU)
          # Default-recommendation: rollout_k=1, epochs<=6
          # -----------------------------
          echo "---- REAL RUN ----"
          if [[ "$USE_RGB" == "1" ]]; then
            python -u ml/train_convlstm.py \
              --metrics-csv "$METRICS" \
              --outdir out \
              --seq-len "$SEQ_LEN" \
              --rollout-k "$K" \
              --epochs "$EPOCHS" \
              --batch-size 2 \
              --use-rgb
          else
            python -u ml/train_convlstm.py \
              --metrics-csv "$METRICS" \
              --outdir out \
              --seq-len "$SEQ_LEN" \
              --rollout-k "$K" \
              --epochs "$EPOCHS" \
              --batch-size 2
          fi

          echo "---- convlstm outputs ----"
          ls -la out/models | grep -i convlstm || true
          ls -la out/viz    | grep -i convlstm || true


      - name: Upload Phase 3/4 outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: rollup_${{ steps.resolve.outputs.day }}
          path: |
            out/${{ steps.resolve.outputs.day }}/daily
            out/${{ steps.resolve.outputs.day }}/phase3_unet_${{ steps.p3train.outputs.outtag }}_thr03
            out/${{ steps.resolve.outputs.day }}/phase4_convlstm
            out/cloud_metrics.csv
            out/masks
            out/models
            out/viz

      - name: Commit results to data (rebase-safe)
        shell: bash
        run: |
          set -euo pipefail
          DAY="${{ steps.resolve.outputs.day }}"

          # Stage outputs
          git add -f data/raw out || true

          # If nothing changed, bail early (but don't fail)
          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "daily rollup + phase2 + phase3(${{
            steps.resolve.outputs.phase3_mode
          }}) + phase4(convlstm optional): $DAY" || true

          # Make push robust against non-fast-forward
          git fetch origin data
          git pull --rebase --autostash origin data

          git push origin data







