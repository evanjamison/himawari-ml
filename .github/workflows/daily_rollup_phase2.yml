name: daily-rollup-phase2

on:
  schedule:
    - cron: "10 9 * * *"
  workflow_dispatch:
    inputs:
      day:
        description: "Optional day (YYYY-MM-DD or YYYYMMDD). Leave blank to auto-detect."
        required: false
        default: ""

permissions:
  contents: write

concurrency:
  group: daily-rollup-phase2
  cancel-in-progress: false

jobs:
  rollup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: data
          fetch-depth: 0

      - name: Configure git identity
        shell: bash
        run: |
          set -euo pipefail
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"

      # Bring code from main into this workspace WITHOUT merging branches
      # IMPORTANT: do NOT overwrite ml/ if you have edits on the data branch.
      - name: Bring pipeline code from main (no merge)
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main --depth=1

          # Pull pipeline + src code from main
          git checkout origin/main -- src scripts requirements.txt pyproject.toml || true

          # Only pull ml/ from main if it doesn't exist on data
          if [[ ! -f "ml/infer_unet_masks.py" ]]; then
            echo "ml/infer_unet_masks.py missing on data branch; pulling ml/ from main..."
            git checkout origin/main -- ml || true
          else
            echo "Keeping ml/ from data branch (ml/infer_unet_masks.py exists)."
          fi

          echo "---- verify filter_black_frames.py exists ----"
          ls -la scripts/pipeline/filter_black_frames.py

          echo "---- verify Phase2 runner exists ----"
          ls -la scripts/pipeline/run_sample_pipeline.py

          echo "---- verify infer script exists ----"
          ls -la ml/infer_unet_masks.py

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Resolve DAY + input roots
        id: resolve
        shell: bash
        run: |
          set -euo pipefail

          RAWROOT="data/raw"
          INPUT_DAY="${{ github.event.inputs.day }}"

          norm_day() {
            [[ "$1" =~ ^[0-9]{8}$ ]] && echo "${1:0:4}-${1:4:2}-${1:6:2}" || echo "$1"
          }

          [[ -d "$RAWROOT" ]] || { echo "ERROR: $RAWROOT missing on data branch"; exit 1; }

          mapfile -t DAYS < <(find "$RAWROOT" -maxdepth 1 -mindepth 1 -type d -name "????-??-??" -printf "%f|%p\n" | sort)

          if [[ ${#DAYS[@]} -eq 0 ]]; then
            echo "ERROR: No YYYY-MM-DD folders under $RAWROOT"
            ls -la "$RAWROOT" || true
            exit 1
          fi

          if [[ -n "$INPUT_DAY" ]]; then
            DAY="$(norm_day "$INPUT_DAY")"
            DAYDIR="$(printf '%s\n' "${DAYS[@]}" | awk -F'|' -v d="$DAY" '$1==d {print $2}' | tail -n 1)"
            [[ -n "$DAYDIR" ]] || { echo "ERROR: day '$DAY' not found under $RAWROOT"; exit 1; }
          else
            LAST="${DAYS[-1]}"
            DAY="${LAST%%|*}"
            DAYDIR="${LAST#*|}"
          fi

          if [[ -d "$DAYDIR/latest" ]]; then
            INROOT="$DAYDIR/latest"
          elif [[ -d "$DAYDIR/sequences" ]]; then
            INROOT="$DAYDIR/sequences"
          else
            echo "ERROR: Neither latest/ nor sequences/ exists in $DAYDIR"
            ls -la "$DAYDIR" || true
            exit 1
          fi

          OUTMASTER="$DAYDIR/master"
          OUTFRAMES="$OUTMASTER/frames"
          OUTDIR="out/$DAY/daily"

          echo "day=$DAY" >> "$GITHUB_OUTPUT"
          echo "daydir=$DAYDIR" >> "$GITHUB_OUTPUT"
          echo "inroot=$INROOT" >> "$GITHUB_OUTPUT"
          echo "outmaster=$OUTMASTER" >> "$GITHUB_OUTPUT"
          echo "outframes=$OUTFRAMES" >> "$GITHUB_OUTPUT"
          echo "outdir=$OUTDIR" >> "$GITHUB_OUTPUT"

      - name: Filter black frames (pre-stage)
        id: filter
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.resolve.outputs.inroot }}"
          DAYDIR="${{ steps.resolve.outputs.daydir }}"

          CLEANROOT="$DAYDIR/filtered"
          QUAR="$DAYDIR/rejects/black"

          mkdir -p "$CLEANROOT" "$QUAR"

          python scripts/pipeline/filter_black_frames.py \
            --inputs "$INROOT" \
            --outdir "$CLEANROOT" \
            --quarantine "$QUAR" \
            --mean-max 6 \
            --std-max 6 \
            --mode copy

          echo "cleanroot=$CLEANROOT" >> "$GITHUB_OUTPUT"

      - name: Stage frames by copying CLEANROOT -> master/frames
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.filter.outputs.cleanroot }}"
          OUTFRAMES="${{ steps.resolve.outputs.outframes }}"

          mkdir -p "$OUTFRAMES"

          shopt -s globstar nullglob
          COPIED=0
          for f in "$INROOT"/**/*.png "$INROOT"/*.png; do
            if [[ -f "$f" ]]; then
              cp -f "$f" "$OUTFRAMES/"
              COPIED=$((COPIED+1))
            fi
          done

          echo "Copied $COPIED png files into $OUTFRAMES"

          if [[ "$COPIED" -eq 0 ]]; then
            echo "ERROR: No PNG frames found under cleaned root: $INROOT"
            exit 1
          fi

      - name: Run Phase 2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${{ steps.resolve.outputs.outdir }}"

          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          python scripts/pipeline/run_sample_pipeline.py \
            --raw-dir "$RAWDIR" \
            --outdir "${{ steps.resolve.outputs.outdir }}" \
            --save-overlays

      # -------------------------
      # Phase 3: U-Net inference (baseline-matched threshold)
      # -------------------------
      - name: Resolve U-Net model checkpoint
        id: model
        shell: bash
        run: |
          set -euo pipefail

          CANON="out/models/unet_cloudmask_latest.pt"
          if [[ -f "$CANON" ]]; then
            echo "model_path=$CANON" >> "$GITHUB_OUTPUT"
            echo "Using canonical: $CANON"
            exit 0
          fi

          echo "Canonical missing: $CANON"
          echo "Searching for newest *.pt under out/models..."
          mapfile -t CANDS < <(find out/models -type f -name "*.pt" -printf "%T@|%p\n" | sort -nr | head -n 1 | cut -d'|' -f2-)

          if [[ ${#CANDS[@]} -eq 0 ]]; then
            echo "ERROR: No model .pt found under out/models in this checkout."
            echo "Fix: commit a model to data branch at out/models/unet_cloudmask_latest.pt"
            exit 1
          fi

          echo "model_path=${CANDS[0]}" >> "$GITHUB_OUTPUT"
          echo "Using newest: ${CANDS[0]}"

      - name: Build a small probe set of frames (fast threshold search)
        id: probe
        shell: bash
        run: |
          set -euo pipefail
          DAY="${{ steps.resolve.outputs.day }}"
          FRAMES="${{ steps.resolve.outputs.outframes }}"
          PROBE_DIR="out/${DAY}/_probe_frames"

          rm -rf "$PROBE_DIR"
          mkdir -p "$PROBE_DIR"

          # Take up to 8 frames spread across the folder
          mapfile -t ALL < <(ls -1 "$FRAMES"/*.png 2>/dev/null | sort)
          N=${#ALL[@]}
          if [[ "$N" -eq 0 ]]; then
            echo "ERROR: No frames found at $FRAMES"
            exit 1
          fi

          WANT=8
          if [[ "$N" -lt "$WANT" ]]; then WANT="$N"; fi

          # Evenly spaced indices
          for i in $(seq 0 $((WANT-1))); do
            idx=$(( i * (N-1) / (WANT-1) ))
            cp -f "${ALL[$idx]}" "$PROBE_DIR/"
          done

          echo "probe_dir=$PROBE_DIR" >> "$GITHUB_OUTPUT"
          echo "Probe frames copied: $(ls -1 "$PROBE_DIR"/*.png | wc -l)"

      - name: Find baseline metrics CSV (Phase 2 output)
        id: basemetrics
        shell: bash
        run: |
          set -euo pipefail
          OUTDIR="${{ steps.resolve.outputs.outdir }}"

          # Common names/locations
          CAND1="$OUTDIR/cloud_metrics.csv"
          CAND2="$OUTDIR/cloud_metrics_unet.csv"
          CAND3="$OUTDIR/cloud_metrics_baseline.csv"

          if [[ -f "$CAND1" ]]; then
            echo "metrics_csv=$CAND1" >> "$GITHUB_OUTPUT"
            echo "Using baseline metrics: $CAND1"
            exit 0
          fi

          # fallback: search within out/$DAY/daily
          echo "Baseline metrics not found at $CAND1; searching under $OUTDIR..."
          FOUND="$(find "$OUTDIR" -maxdepth 3 -type f -name "*.csv" | head -n 50 || true)"
          echo "$FOUND" | sed -n '1,50p'

          # pick the first csv that looks like a baseline cloud metrics file
          PICK="$(python - <<'PY'
import os, sys
from pathlib import Path
outdir = Path(os.environ["OUTDIR"])
cands = list(outdir.rglob("*.csv"))
# prefer names containing "cloud" and "metrics" but NOT "unet"
def score(p: Path) -> int:
    s = p.name.lower()
    sc = 0
    if "cloud" in s: sc += 3
    if "metrics" in s: sc += 3
    if "unet" in s: sc -= 5
    return sc
cands = sorted(cands, key=lambda p: (score(p), p.stat().st_mtime), reverse=True)
print(str(cands[0]) if cands else "")
PY
)"
          if [[ -z "$PICK" ]]; then
            echo "ERROR: Could not find any baseline metrics CSV under $OUTDIR"
            exit 1
          fi

          echo "metrics_csv=$PICK" >> "$GITHUB_OUTPUT"
          echo "Using baseline metrics: $PICK"
        env:
          OUTDIR: ${{ steps.resolve.outputs.outdir }}

      - name: Pick threshold to match baseline cloud fraction (robust)
        id: autothr
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          PROBE_FRAMES="${{ steps.probe.outputs.probe_dir }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"
          METRICS_CSV="${{ steps.basemetrics.outputs.metrics_csv }}"

          echo "DAY=$DAY"
          echo "PROBE_FRAMES=$PROBE_FRAMES"
          echo "MODEL_PATH=$MODEL_PATH"
          echo "METRICS_CSV=$METRICS_CSV"
          ls -la "$MODEL_PATH" || true
          ls -la "$PROBE_FRAMES" | sed -n '1,50p' || true
          head -n 5 "$METRICS_CSV" || true

          export DAY PROBE_FRAMES MODEL_PATH METRICS_CSV

          python - <<'PY'
import os, shutil, subprocess
from pathlib import Path
import numpy as np
import pandas as pd
from PIL import Image

day = os.environ["DAY"]
probe_frames = os.environ["PROBE_FRAMES"]
model = os.environ["MODEL_PATH"]
metrics_csv = os.environ["METRICS_CSV"]

df = pd.read_csv(metrics_csv)

# Try to find a reasonable baseline fraction column
cols = [c.lower() for c in df.columns]
pick = None
for cand in ["cloud_frac", "cloud_fraction", "cloud_pct", "cloud_percent", "frac_cloud"]:
    for c in df.columns:
        if c.lower() == cand:
            pick = c
            break
    if pick: break

if pick is None:
    # fallback: any numeric column containing "cloud" but not "unet"
    numeric = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
    cloudish = [c for c in numeric if ("cloud" in c.lower() and "unet" not in c.lower())]
    pick = cloudish[0] if cloudish else None

if pick is None:
    raise SystemExit(f"Could not find baseline cloud fraction column in {metrics_csv}. Columns: {list(df.columns)}")

baseline_target = float(np.nanmean(df[pick].values))
# If baseline is in [0,100], convert to [0,1]
if baseline_target > 1.5:
    baseline_target = baseline_target / 100.0

print(f"Baseline target from '{pick}': {baseline_target:.6f} (fraction)")

thresholds = [0.05, 0.08, 0.10, 0.12, 0.15, 0.18, 0.20, 0.25, 0.30]
best = None

out_root = Path("out") / day
probe_out_root = out_root / "_thr_probe"
if probe_out_root.exists():
    shutil.rmtree(probe_out_root)
probe_out_root.mkdir(parents=True, exist_ok=True)

def avg_white(mask_dir: Path) -> float:
    files = sorted(mask_dir.glob("*.png"))
    if not files:
        return 0.0
    whites = []
    for f in files:
        a = np.array(Image.open(f))
        whites.append(float((a > 0).mean()))  # fraction
    return float(np.mean(whites))

for thr in thresholds:
    outdir = probe_out_root / f"thr_{int(thr*100):02d}"
    if outdir.exists():
        shutil.rmtree(outdir)
    outdir.mkdir(parents=True, exist_ok=True)

    cmd = [
        "python", "ml/infer_unet_masks.py",
        "--frames", probe_frames,
        "--outdir", str(outdir),
        "--ckpt", model,
        "--threshold", str(thr),
        "--image-size", "256",
        "--device", "cpu",
    ]
    subprocess.check_call(cmd)

    mdir = outdir / "masks_unet"
    unet_frac = avg_white(mdir)
    diff = abs(unet_frac - baseline_target)

    print(f"thr={thr:.2f} -> unet_cloud_frac={unet_frac:.6f} diff={diff:.6f}")

    if best is None or diff < best["diff"]:
        best = {"thr": thr, "diff": diff, "unet_frac": unet_frac}

print("BEST", best)
Path("chosen_thr.txt").write_text(str(best["thr"]))
PY

      - name: Export chosen threshold
        id: thr
        shell: bash
        run: |
          set -euo pipefail
          best_thr="$(cat chosen_thr.txt)"
          echo "threshold=$best_thr" >> "$GITHUB_OUTPUT"
          echo "Chosen threshold: $best_thr"

      - name: Run Phase 3 (U-Net inference) using ml/infer_unet_masks.py (baseline-matched threshold)
        id: phase3
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          FRAMES="${{ steps.resolve.outputs.outframes }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"
          THR="${{ steps.thr.outputs.threshold }}"

          THR_TAG="$(python - <<PY
t=float("$THR")
print(f"{int(round(t*100)):02d}")
PY
)"
          OUTDIR="out/${DAY}/phase3_unet_v2_thr${THR_TAG}"

          echo "DAY=$DAY"
          echo "FRAMES=$FRAMES"
          echo "MODEL_PATH=$MODEL_PATH"
          echo "THR=$THR  (tag=$THR_TAG)"
          echo "OUTDIR=$OUTDIR"

          mkdir -p "$OUTDIR"

          python ml/infer_unet_masks.py \
            --frames "$FRAMES" \
            --outdir "$OUTDIR" \
            --ckpt "$MODEL_PATH" \
            --recursive \
            --threshold "$THR" \
            --image-size 256 \
            --device cpu

          echo "---- debug: white pixel % on first 15 masks ----"
          python - <<'PY'
from pathlib import Path
import numpy as np
from PIL import Image
import os

day = os.environ["DAY"]
root = Path("out") / day
cand = sorted([p for p in root.glob("phase3_unet_v2_thr*") if p.is_dir()],
              key=lambda p: p.stat().st_mtime, reverse=True)
outdir = cand[0] if cand else None
p = outdir / "masks_unet" if outdir else (root / "masks_unet")

files = sorted(p.glob("*.png"))
print("masks_unet:", str(p))
print("count:", len(files))
for f in files[:15]:
    a = np.array(Image.open(f))
    white = float((a > 0).mean()) * 100.0
    print(f.name, "min/max", int(a.min()), int(a.max()), "white%:", round(white, 4))
PY
        env:
          DAY: ${{ steps.resolve.outputs.day }}

      - name: DEBUG montage (TEMP): RGB + prob heatmap + mask for one frame
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          FRAMES="${{ steps.resolve.outputs.outframes }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"
          THR="${{ steps.thr.outputs.threshold }}"
          OUTROOT="out/${DAY}"

          python - <<'PY'
import os
from pathlib import Path
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt

import torch

day = os.environ["DAY"]
frames_dir = Path(os.environ["FRAMES"])
ckpt = os.environ["MODEL_PATH"]
thr = float(os.environ["THR"])
outroot = Path(os.environ["OUTROOT"])

# pick a deterministic sample frame
frames = sorted(frames_dir.glob("*.png"))
if not frames:
    raise SystemExit(f"No frames in {frames_dir}")
f = frames[len(frames)//2]  # middle frame

# Import model definition from your inference script (guaranteed consistent)
import importlib.util
spec = importlib.util.spec_from_file_location("infer", str(Path("ml/infer_unet_masks.py")))
infer = importlib.util.module_from_spec(spec)
spec.loader.exec_module(infer)  # type: ignore

state = torch.load(ckpt, map_location="cpu")
model = infer.load_model(Path(ckpt), base_ch=None, depth=None, device="cpu")
model.eval()

img = Image.open(f).convert("RGB").resize((256,256), Image.BILINEAR)
x = np.asarray(img).astype("float32")/255.0
xt = torch.from_numpy(x).permute(2,0,1).unsqueeze(0)

with torch.no_grad():
    logits = model(xt)
    prob = torch.sigmoid(logits)[0,0].cpu().numpy()

mask = (prob >= thr).astype(np.uint8)*255

# Save montage
outroot.mkdir(parents=True, exist_ok=True)
fig = plt.figure(figsize=(9,3))
ax1 = fig.add_subplot(1,3,1); ax1.imshow(img); ax1.set_title("RGB"); ax1.axis("off")
ax2 = fig.add_subplot(1,3,2); ax2.imshow(prob, vmin=0, vmax=1); ax2.set_title(f"Prob (min={prob.min():.3f} max={prob.max():.3f})"); ax2.axis("off")
ax3 = fig.add_subplot(1,3,3); ax3.imshow(mask, cmap="gray"); ax3.set_title(f"Mask @ thr={thr:.2f}"); ax3.axis("off")
p = outroot / "debug_phase3_montage.png"
fig.tight_layout()
fig.savefig(p, dpi=160)
print("Wrote:", p)
PY
        env:
          DAY: ${{ steps.resolve.outputs.day }}
          FRAMES: ${{ steps.resolve.outputs.outframes }}
          MODEL_PATH: ${{ steps.model.outputs.model_path }}
          THR: ${{ steps.thr.outputs.threshold }}
          OUTROOT: out/${{ steps.resolve.outputs.day }}

      - name: Upload Phase 3 outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: phase3_unet_${{ steps.resolve.outputs.day }}
          path: |
            out/${{ steps.resolve.outputs.day }}/phase3_unet_v2_thr*
            out/${{ steps.resolve.outputs.day }}/debug_phase3_montage.png

      - name: Commit results to data
        shell: bash
        run: |
          set -euo pipefail
          git add -f data/raw out || true
          git commit -m "daily rollup + phase2 + phase3(baseline-matched thr): ${{ steps.resolve.outputs.day }}" || echo "No changes"
          git push origin data



