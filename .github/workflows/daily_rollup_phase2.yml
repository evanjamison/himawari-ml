name: daily-rollup-phase2

on:
  schedule:
    - cron: "10 9 * * *"
  workflow_dispatch:
    inputs:
      day:
        description: "Optional day (YYYY-MM-DD or YYYYMMDD). Leave blank to auto-detect."
        required: false
        default: ""

permissions:
  contents: write

concurrency:
  group: daily-rollup-phase2
  cancel-in-progress: false

jobs:
  rollup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout data branch
        uses: actions/checkout@v4
        with:
          ref: data
          fetch-depth: 0

      - name: Configure git identity
        shell: bash
        run: |
          set -euo pipefail
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@users.noreply.github.com"

      # Bring code from main into this workspace WITHOUT merging branches
      - name: Bring pipeline code from main (no merge)
        shell: bash
        run: |
          set -euo pipefail
          git fetch origin main --depth=1
          git checkout origin/main -- src scripts ml requirements.txt pyproject.toml || true

          echo "---- verify filter_black_frames.py exists ----"
          ls -la scripts/pipeline/filter_black_frames.py

          echo "---- verify phase3 runner exists (optional) ----"
          ls -la scripts/pipeline/run_phase3_unet_daily.py || true

          echo "---- verify teacher baseline exists ----"
          ls -la scripts/experiments/segmentation/cloud_mask_baseline_v2.py

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .
          # âœ… baseline v2 imports cv2; use headless OpenCV on GH runners
          pip install opencv-python-headless

      - name: Resolve DAY + input roots
        id: resolve
        shell: bash
        run: |
          set -euo pipefail

          RAWROOT="data/raw"
          INPUT_DAY="${{ github.event.inputs.day }}"

          norm_day() {
            [[ "$1" =~ ^[0-9]{8}$ ]] && echo "${1:0:4}-${1:4:2}-${1:6:2}" || echo "$1"
          }

          [[ -d "$RAWROOT" ]] || { echo "ERROR: $RAWROOT missing on data branch"; exit 1; }

          mapfile -t DAYS < <(find "$RAWROOT" -maxdepth 1 -mindepth 1 -type d -name "????-??-??" -printf "%f|%p\n" | sort)

          if [[ ${#DAYS[@]} -eq 0 ]]; then
            echo "ERROR: No YYYY-MM-DD folders under $RAWROOT"
            ls -la "$RAWROOT" || true
            exit 1
          fi

          if [[ -n "$INPUT_DAY" ]]; then
            DAY="$(norm_day "$INPUT_DAY")"
            DAYDIR="$(printf '%s\n' "${DAYS[@]}" | awk -F'|' -v d="$DAY" '$1==d {print $2}' | tail -n 1)"
            [[ -n "$DAYDIR" ]] || { echo "ERROR: day '$DAY' not found under $RAWROOT"; exit 1; }
          else
            LAST="${DAYS[-1]}"
            DAY="${LAST%%|*}"
            DAYDIR="${LAST#*|}"
          fi

          if [[ -d "$DAYDIR/latest" ]]; then
            INROOT="$DAYDIR/latest"
          elif [[ -d "$DAYDIR/sequences" ]]; then
            INROOT="$DAYDIR/sequences"
          else
            echo "ERROR: Neither latest/ nor sequences/ exists in $DAYDIR"
            ls -la "$DAYDIR" || true
            exit 1
          fi

          OUTMASTER="$DAYDIR/master"
          OUTFRAMES="$OUTMASTER/frames"
          OUTDIR="out/$DAY/daily"

          echo "day=$DAY" >> "$GITHUB_OUTPUT"
          echo "daydir=$DAYDIR" >> "$GITHUB_OUTPUT"
          echo "inroot=$INROOT" >> "$GITHUB_OUTPUT"
          echo "outmaster=$OUTMASTER" >> "$GITHUB_OUTPUT"
          echo "outframes=$OUTFRAMES" >> "$GITHUB_OUTPUT"
          echo "outdir=$OUTDIR" >> "$GITHUB_OUTPUT"

      - name: Filter black frames (pre-stage)
        id: filter
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.resolve.outputs.inroot }}"
          DAYDIR="${{ steps.resolve.outputs.daydir }}"

          CLEANROOT="$DAYDIR/filtered"
          QUAR="$DAYDIR/rejects/black"

          mkdir -p "$CLEANROOT" "$QUAR"

          python scripts/pipeline/filter_black_frames.py \
            --inputs "$INROOT" \
            --outdir "$CLEANROOT" \
            --quarantine "$QUAR" \
            --mean-max 6 \
            --std-max 6 \
            --mode copy

          echo "cleanroot=$CLEANROOT" >> "$GITHUB_OUTPUT"

      - name: Stage frames by copying CLEANROOT -> master/frames
        shell: bash
        run: |
          set -euo pipefail

          INROOT="${{ steps.filter.outputs.cleanroot }}"
          OUTFRAMES="${{ steps.resolve.outputs.outframes }}"

          mkdir -p "$OUTFRAMES"

          shopt -s globstar nullglob
          COPIED=0
          for f in "$INROOT"/**/*.png "$INROOT"/*.png; do
            if [[ -f "$f" ]]; then
              cp -f "$f" "$OUTFRAMES/"
              COPIED=$((COPIED+1))
            fi
          done

          echo "Copied $COPIED png files into $OUTFRAMES"

          if [[ "$COPIED" -eq 0 ]]; then
            echo "ERROR: No PNG frames found under cleaned root: $INROOT"
            exit 1
          fi

      - name: Run Phase 2
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p "${{ steps.resolve.outputs.outdir }}"

          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          python scripts/pipeline/run_sample_pipeline.py \
            --raw-dir "$RAWDIR" \
            --outdir "${{ steps.resolve.outputs.outdir }}" \
            --save-overlays

      # ============================================================
      # Phase 3 (v2): Teacher -> Train -> Infer  (matches your local)
      # ============================================================

      - name: Phase 3A - Build teacher masks + cloud_metrics.csv (baseline v2)
        shell: bash
        run: |
          set -euo pipefail
          RAWDIR="${{ steps.resolve.outputs.outframes }}"

          # Produces:
          #   out/cloud_metrics.csv
          #   out/masks/...
          python scripts/experiments/segmentation/cloud_mask_baseline_v2.py \
            --raw-dir "$RAWDIR" \
            --outdir out \
            --image-size 256 \
            --save-overlays

          echo "---- verify teacher outputs ----"
          ls -la out/cloud_metrics.csv
          ls -la out/masks | head -n 20 || true
          
          python - << 'PY'
          import pandas as pd
          df = pd.read_csv("out/cloud_metrics.csv")
          # try common names
          cols = [c for c in df.columns if "cloud" in c.lower() and "fraction" in c.lower()]
          print("cloud fraction cols:", cols)
          if cols:
              c = cols[0]
              print(df[c].describe())
              print("quantiles:", df[c].quantile([0.01,0.05,0.25,0.5,0.75,0.95,0.99]).to_dict())
          PY


      - name: Phase 3B - Train U-Net on teacher metrics
        shell: bash
        run: |
          set -euo pipefail

          # Your local run:
          # python ml/train_unet.py --metrics-csv out/cloud_metrics.csv --outdir out/models ...
          python ml/train_unet.py \
            --metrics-csv out/cloud_metrics.csv \
            --outdir out \
            --epochs 30 \
            --batch-size 4 \
            --lr 3e-4 \
            --base-ch 32 \
            --augment \
            --bce-weight 0.1 \
            --use-disk-mask \
            --pos-weight auto \
            --split-by-time


          echo "---- list models ----"
          find out/models -type f -name "*.pt" -maxdepth 4 -print || true
          python - <<'PY'
          import torch
          ckpt = torch.load("out/models/unet_cloudmask_latest.pt", map_location="cpu")
          print("using run_id:", ckpt.get("config", {}).get("run_id", None))
          print("pos_weight:", ckpt.get("config", {}).get("pos_weight", None))
          print("use_disk_mask:", ckpt.get("config", {}).get("use_disk_mask", None))
          PY


      - name: Phase 3C - Resolve trained checkpoint from newest metrics (robust)
        shell: bash
        run: |
          set -euo pipefail
      
          echo "---- after training, list recent artifacts ----"
          ls -lt out/models | head -n 80
      
          # pick newest *.metrics.csv and use corresponding .pt
          newest_metrics="$(ls -t out/models/*.metrics.csv | head -n 1)"
          echo "Newest metrics: ${newest_metrics}"
      
          ckpt="${newest_metrics%.metrics.csv}.pt"
          echo "Using checkpoint: ${ckpt}"
      
          if [[ ! -f "${ckpt}" ]]; then
            echo "ERROR: checkpoint not found: ${ckpt}"
            exit 1
          fi
      
          # copy to canonical name
          cp -f "${ckpt}" out/models/unet_cloudmask_latest.pt
          echo "Wrote canonical checkpoint: out/models/unet_cloudmask_latest.pt"
      
          ls -lh out/models/unet_cloudmask_latest.pt

      - name: Debug checkpoint identity
        shell: bash
        run: |
          ls -lh out/models
          python - <<'PY'
          import torch
          p = "out/models/unet_cloudmask_latest.pt"
          print("exists:", p)
          ckpt = torch.load(p, map_location="cpu")
          print("ckpt type:", type(ckpt))
          if isinstance(ckpt, dict):
              print("run_id:", ckpt.get("config", {}).get("run_id"))
              print("use_disk_mask:", ckpt.get("config", {}).get("use_disk_mask"))
              print("pos_weight:", ckpt.get("config", {}).get("pos_weight"))
          PY

      - name: Phase 3D - Infer masks (threshold 0.3) + debug pixel stats
        shell: bash
        run: |
          set -euo pipefail

          DAY="${{ steps.resolve.outputs.day }}"
          RAWDIR="${{ steps.resolve.outputs.outframes }}"
          MODEL_PATH="${{ steps.model.outputs.model_path }}"

          OUTDIR="out/$DAY/phase3_unet_v2_thr03"
          mkdir -p "$OUTDIR"

          python ml/infer_unet_masks.py \
            --frames "$RAWDIR" \
            --outdir "$OUTDIR" \
            --ckpt "$MODEL_PATH" \
            --recursive \
            --threshold 0.5 \
            --image-size 256 \
            --device cpu

          echo "---- debug: check masks not-empty (white pixel %) ----"
          python - <<'PY'
          from pathlib import Path
          import numpy as np
          from PIL import Image

          outdir = Path("out") / "${{ steps.resolve.outputs.day }}" / "phase3_unet_v2_thr03" / "masks_unet"
          files = sorted(outdir.glob("*.png"))
          print("masks_unet:", outdir)
          print("count:", len(files))
          if not files:
            raise SystemExit("No mask PNGs found.")

          # sample first 5
          for f in files[:5]:
            a = np.array(Image.open(f))
            white = (a >= 128).mean() * 100.0
            print(f.name, "shape", a.shape, "min/max", int(a.min()), int(a.max()), "white%:", round(white, 4))
          PY

          echo "---- phase3 outputs ----"
          ls -la "$OUTDIR" || true
          ls -la "$OUTDIR/masks_unet" | head -n 20 || true
          ls -la "$OUTDIR/cloud_metrics_unet.csv" || true

          python - << 'PY'
          from pathlib import Path
          from PIL import Image
          import numpy as np
          
          masks = sorted(Path("out/2026-01-29/phase3_unet_v2_thr03/masks_unet").glob("*.png"))[:10]
          print("checking", len(masks), "masks")
          bad = 0
          for p in masks:
              a = np.array(Image.open(p).convert("L"))
              if a.max() == 0:
                  bad += 1
              print(p.name, "min/max", int(a.min()), int(a.max()), "white%", float((a>0).mean()))
          if bad == len(masks) and len(masks)>0:
              raise SystemExit("All checked masks are empty (all black). Failing.")
          PY



      - name: Upload Phase 3 outputs (artifact)
        uses: actions/upload-artifact@v4
        with:
          name: phase3_unet_v2_${{ steps.resolve.outputs.day }}
          path: |
            out/${{ steps.resolve.outputs.day }}/phase3_unet_v2_thr03
            out/cloud_metrics.csv
            out/masks
            out/models/unet_cloudmask_latest.pt

      - name: Commit results to data
        shell: bash
        run: |
          set -euo pipefail
          DAY="${{ steps.resolve.outputs.day }}"

          git add -f data/raw out || true
          git commit -m "daily rollup + phase2 + phase3(v2 teacher->train->infer): $DAY" || echo "No changes"
          git push origin data





